{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c330776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80ac226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24460651",
   "metadata": {},
   "source": [
    "# Read experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35486fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualtrics data, extra rows contain headers\n",
    "df_headers = pd.read_csv('/'.join(['data','AI+Learning+Research.csv']), header=[0,1,2])\n",
    "# Choice fields stored as text strings\n",
    "df_original = pd.read_csv('/'.join(['data','AI+Learning+Research.csv']), header=[0], skiprows=[1, 2], parse_dates=['StartDate', 'EndDate', 'RecordedDate'])\n",
    "df_values = pd.read_csv('/'.join(['data','AI+Learning+Research_values.csv']), header=[0], skiprows=[1, 2])\n",
    "# Add suffix to value columns\n",
    "suffix = '_val'\n",
    "df_values = df_values.add_suffix(suffix)\n",
    "df_values['ResponseId'] = df_values['ResponseId'+suffix]\n",
    "# Specify the column names for merging\n",
    "merge_columns = list(map(lambda col: col + suffix, [\n",
    "    'Q2_1', 'Q2_2', 'Q2_3', 'Q2_4', \n",
    "    'Q3_1', 'Q3_2', 'Q3_3', 'Q3_4', \n",
    "    'Q6', 'Q7', \n",
    "    'Q18_1', 'Q18_2', 'Q18_3', 'Q18_4', 'Q18_5', 'Q18_6', \n",
    "    'Q19'\n",
    "]))\n",
    "# Merge the values\n",
    "df_merged = df_original.merge(df_values[merge_columns + ['ResponseId']], on='ResponseId', how='left')\n",
    "\n",
    "df = df_merged.copy()\n",
    "\n",
    "# Sort columns alphabetically\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "\n",
    "# Define experiment start and end dates\n",
    "experiment_start = pd.to_datetime('February 19, 2024')\n",
    "experiment_end = pd.to_datetime('February 24, 2024') # One day after the experiment\n",
    "df = df[(df['StartDate'] >= experiment_start) & (df['EndDate'] <= experiment_end)]\n",
    "df_datebound = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fd793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually extracted data\n",
    "df_manual = pd.read_csv('/'.join(['output','filtered_df.csv']))\n",
    "\n",
    "df_errors = pd.read_csv('/'.join(['data','BRC FC W2 Lab Log Spring 24.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da6764a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered/timeframe/total: 311/354/378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>334</th>\n",
       "      <th>333</th>\n",
       "      <th>332</th>\n",
       "      <th>331</th>\n",
       "      <th>330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DistributionChannel</th>\n",
       "      <td>anonymous</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>anonymous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <td>808</td>\n",
       "      <td>767</td>\n",
       "      <td>918</td>\n",
       "      <td>894</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EndDate</th>\n",
       "      <td>2024-02-23 17:27:22</td>\n",
       "      <td>2024-02-23 17:27:14</td>\n",
       "      <td>2024-02-23 16:32:15</td>\n",
       "      <td>2024-02-23 16:32:14</td>\n",
       "      <td>2024-02-23 16:31:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExternalReference</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finished</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResponseId</th>\n",
       "      <td>R_1eOZk23XMHZMM4f</td>\n",
       "      <td>R_5V1SmFk9wLGCcaV</td>\n",
       "      <td>R_1dXY5K6kRdWhztv</td>\n",
       "      <td>R_3v2GsCa5UlKXPES</td>\n",
       "      <td>R_5S7eRhBVhkocrkM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StartDate</th>\n",
       "      <td>2024-02-23 17:13:54</td>\n",
       "      <td>2024-02-23 17:14:26</td>\n",
       "      <td>2024-02-23 16:16:56</td>\n",
       "      <td>2024-02-23 16:17:20</td>\n",
       "      <td>2024-02-23 16:14:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>IP Address</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>IP Address</td>\n",
       "      <td>IP Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserLanguage</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition_experiment</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       334                  333  \\\n",
       "DistributionChannel              anonymous            anonymous   \n",
       "Duration (in seconds)                  808                  767   \n",
       "EndDate                2024-02-23 17:27:22  2024-02-23 17:27:14   \n",
       "ExternalReference                      NaN                  NaN   \n",
       "Finished                              True                 True   \n",
       "...                                    ...                  ...   \n",
       "ResponseId               R_1eOZk23XMHZMM4f    R_5V1SmFk9wLGCcaV   \n",
       "StartDate              2024-02-23 17:13:54  2024-02-23 17:14:26   \n",
       "Status                          IP Address           IP Address   \n",
       "UserLanguage                            EN                   EN   \n",
       "condition_experiment                     0                    1   \n",
       "\n",
       "                                       332                  331  \\\n",
       "DistributionChannel              anonymous            anonymous   \n",
       "Duration (in seconds)                  918                  894   \n",
       "EndDate                2024-02-23 16:32:15  2024-02-23 16:32:14   \n",
       "ExternalReference                      NaN                  NaN   \n",
       "Finished                              True                 True   \n",
       "...                                    ...                  ...   \n",
       "ResponseId               R_1dXY5K6kRdWhztv    R_3v2GsCa5UlKXPES   \n",
       "StartDate              2024-02-23 16:16:56  2024-02-23 16:17:20   \n",
       "Status                          IP Address           IP Address   \n",
       "UserLanguage                            EN                   EN   \n",
       "condition_experiment                     1                    0   \n",
       "\n",
       "                                       330  \n",
       "DistributionChannel              anonymous  \n",
       "Duration (in seconds)                 1028  \n",
       "EndDate                2024-02-23 16:31:34  \n",
       "ExternalReference                      NaN  \n",
       "Finished                              True  \n",
       "...                                    ...  \n",
       "ResponseId               R_5S7eRhBVhkocrkM  \n",
       "StartDate              2024-02-23 16:14:25  \n",
       "Status                          IP Address  \n",
       "UserLanguage                            EN  \n",
       "condition_experiment                     0  \n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out errors from df\n",
    "df = df[~df['Q1'].isin(df_errors['Participant ID'])]\n",
    "\n",
    "# Check for non-participants\n",
    "df = df[df['Q1'].str.isdigit()]\n",
    "\n",
    "# Check for users that did not finish the test properly\n",
    "df = df[df['Progress'].astype(int)==100]\n",
    "\n",
    "# Drop duplicates in the Participant ID, only keeping the latest recorded submission\n",
    "df = df.sort_values(by='RecordedDate', ascending=False).drop_duplicates(subset=['Q1'])\n",
    "\n",
    "# Set experiment condition to 1 if the special condition applies, or 0 if the control is in place\n",
    "def set_condition_experiment(row):\n",
    "    if pd.notna(row['Q10']) or pd.notna(row['Q12']):\n",
    "        return 1\n",
    "    elif pd.notna(row['Q14']) or pd.notna(row['Q17']):\n",
    "        return 0\n",
    "    else:\n",
    "        return pd.NA\n",
    "df['condition_experiment'] = df.apply(set_condition_experiment, axis=1)\n",
    "df = df[df['condition_experiment'] != pd.NA]\n",
    "\n",
    "# Filtered data\n",
    "df_filtered = df.copy()\n",
    "\n",
    "# Filtered totals\n",
    "print(f\"filtered/timeframe/total: {len(df_filtered)}/{len(df_datebound)}/{len(df_original)}\")\n",
    "\n",
    "df.to_csv('/'.join(['output','clean.csv']), index=False)\n",
    "df.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab15566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1 = df.dropna(subset=['Q10'])\n",
    "new_df2 = df.dropna(subset=['Q12'])\n",
    "new_df3 = df.dropna(subset=['Q14'])\n",
    "new_df4 = df.dropna(subset=['Q17'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8386a5e",
   "metadata": {},
   "source": [
    "# Jaccard distance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da841fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import nltk # First time only: nltk.download('all')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# create preprocess_text function\n",
    "def tokenize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "    return lemmatized_tokens\n",
    " \n",
    "def jaccard_similarity(set1, set2):\n",
    "    # intersection of two sets\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    # Unions of two sets\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union\n",
    "\n",
    "# Tokenizing each question list\n",
    "tokens_chatgpt = tokenize_text(\n",
    "\"\"\"\n",
    "Pros of Social Media:\n",
    "Connectivity: Enables instant communication and connection with friends, family, and a global network.\n",
    "Information Sharing: Facilitates the rapid dissemination of news, trends, and information.\n",
    "\n",
    "Cons of Social Media:\n",
    "Privacy Concerns: Raises issues regarding the protection of personal information and privacy.\n",
    "Misinformation: Provides a platform for the spread of false information and rumors.\n",
    "\"\"\"\n",
    ")\n",
    "tokens_treatment1 = df['Q10'].apply(tokenize_text)\n",
    "tokens_treatment2 = df['Q12'].apply(tokenize_text)\n",
    "tokens_control1 = df['Q14'].apply(tokenize_text)\n",
    "tokens_control2 = df['Q17'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f6cda6",
   "metadata": {},
   "source": [
    "# Calculate the Jaccard index between product first and final writing in control and treatment condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d09a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating jaccard distance between first and final writing for control and treatment\n",
    "for i in df.index:\n",
    "    tokens1 = tokens_treatment1[i]\n",
    "    tokens2 = tokens_treatment2[i]\n",
    "    if tokens1 and tokens2:\n",
    "        df.loc[i, 'jaccard_similarity'] = jaccard_similarity(set(tokens1), set(tokens2))\n",
    "    tokens1 = tokens_control1[i]\n",
    "    tokens2 = tokens_control2[i]\n",
    "    if tokens1 and tokens2:\n",
    "        df.loc[i, 'jaccard_similarity'] = jaccard_similarity(set(tokens1), set(tokens2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2b90a",
   "metadata": {},
   "source": [
    "# There is not significant difference between Jaccard index of (first and final writing) in control and treatment condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41f8e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -1.3195290320357356\n",
      "P-Value: 0.1879723153689186\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "result_df_0 = df[df['condition_experiment'] == 0]['jaccard_similarity']\n",
    "result_df_1 = df[df['condition_experiment'] == 1]['jaccard_similarity']\n",
    "\n",
    "column_0 = result_df_0.sort_values()\n",
    "column_1 = result_df_1.sort_values()\n",
    "\n",
    "# Perform the t-test\n",
    "t_statistic, p_value = stats.ttest_ind(column_0, column_1, nan_policy='omit')\n",
    "\n",
    "# Display the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b59ed9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q12</th>\n",
       "      <th>jaccard_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Pros: \\n1. easy to reach out friends and famil...</td>\n",
       "      <td>i think the chatgpt's answer is better than mi...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Pros of social media\\n1. I get a chance to rec...</td>\n",
       "      <td>Pros of Social Media:\\nConnectivity: Enables i...</td>\n",
       "      <td>0.067797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Pros of Social Media:\\n1. searchability: findi...</td>\n",
       "      <td>Pros of Social Media:\\nConnectivity: Enables i...</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>increased anxiety is a con\\nwaste of time is a...</td>\n",
       "      <td>I would stick to mine above. Chat gpt gives br...</td>\n",
       "      <td>0.139535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Pros:\\n1. Connectivity: Allows friendships and...</td>\n",
       "      <td>Pros of Social Media:\\nConnectivity: Enables i...</td>\n",
       "      <td>0.140845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Pros of Social Media:\\n1) Connectivity: Enable...</td>\n",
       "      <td>Pros of Social Media:\\n1) Connectivity: Enable...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Pros:\\n\\nGlobal sharing: Ability to connect wi...</td>\n",
       "      <td>Pros:\\n\\nGlobal sharing: Ability to connect wi...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Pros of social media:\\n    1. Connection: I ca...</td>\n",
       "      <td>Pros of social media:\\n1. Connection: I can co...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Pros of Social Media:\\n1. Interaction: being a...</td>\n",
       "      <td>Pros of Social Media:\\n1. Interaction: being a...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Pros: people have easier way to connect with p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Q10  \\\n",
       "86   Pros: \\n1. easy to reach out friends and famil...   \n",
       "174  Pros of social media\\n1. I get a chance to rec...   \n",
       "46   Pros of Social Media:\\n1. searchability: findi...   \n",
       "78   increased anxiety is a con\\nwaste of time is a...   \n",
       "284  Pros:\\n1. Connectivity: Allows friendships and...   \n",
       "..                                                 ...   \n",
       "195  Pros of Social Media:\\n1) Connectivity: Enable...   \n",
       "212  Pros:\\n\\nGlobal sharing: Ability to connect wi...   \n",
       "52   Pros of social media:\\n    1. Connection: I ca...   \n",
       "179  Pros of Social Media:\\n1. Interaction: being a...   \n",
       "241  Pros: people have easier way to connect with p...   \n",
       "\n",
       "                                                   Q12  jaccard_similarity  \n",
       "86   i think the chatgpt's answer is better than mi...            0.000000  \n",
       "174  Pros of Social Media:\\nConnectivity: Enables i...            0.067797  \n",
       "46   Pros of Social Media:\\nConnectivity: Enables i...            0.097561  \n",
       "78   I would stick to mine above. Chat gpt gives br...            0.139535  \n",
       "284  Pros of Social Media:\\nConnectivity: Enables i...            0.140845  \n",
       "..                                                 ...                 ...  \n",
       "195  Pros of Social Media:\\n1) Connectivity: Enable...            1.000000  \n",
       "212  Pros:\\n\\nGlobal sharing: Ability to connect wi...            1.000000  \n",
       "52   Pros of social media:\\n1. Connection: I can co...            1.000000  \n",
       "179  Pros of Social Media:\\n1. Interaction: being a...            1.000000  \n",
       "241                                                NaN                 NaN  \n",
       "\n",
       "[158 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['condition_experiment'] == 1][['Q10','Q12','jaccard_similarity']].sort_values(by='jaccard_similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d99644c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     jaccard_similarity  jaccard_similarity\n",
      "133            0.688525            0.674419\n",
      "134            0.690909            0.690141\n",
      "135            0.692308            0.703704\n",
      "136            0.709091            0.727273\n",
      "137            0.718750            0.772727\n",
      "138            0.732394            0.844444\n",
      "139            0.732394            0.918033\n",
      "140            0.754717            0.931818\n",
      "141            0.818182            0.941176\n",
      "142            0.835616            0.951220\n",
      "143            0.859375            0.958333\n",
      "144            0.901961            0.958333\n",
      "145            0.914894            0.986301\n",
      "146            0.930233            1.000000\n",
      "147            0.953488            1.000000\n",
      "148            0.979167            1.000000\n",
      "149            1.000000            1.000000\n",
      "150            1.000000            1.000000\n",
      "151            1.000000            1.000000\n",
      "152            1.000000            1.000000\n",
      "153                 NaN            1.000000\n",
      "154                 NaN            1.000000\n",
      "155                 NaN            1.000000\n",
      "156                 NaN            1.000000\n",
      "157                 NaN                 NaN\n"
     ]
    }
   ],
   "source": [
    "sorted_result_df_0 = result_df_0.sort_values().reset_index(drop=True)\n",
    "sorted_result_df_1 = result_df_1.sort_values().reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrames\n",
    "print(pd.concat([sorted_result_df_0, sorted_result_df_1], axis=1).tail(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39677cb",
   "metadata": {},
   "source": [
    "# Testing final writing against ChatGPT response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7c5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating jaccard distance between ChatGPT and final writing for control and treatment\n",
    "for i in df.index:\n",
    "    tokens = tokens_treatment2[i]\n",
    "    if tokens:\n",
    "        df.loc[i, 'jaccard_gpt'] = jaccard_similarity(set(tokens_chatgpt), set(tokens))\n",
    "    tokens = tokens_control2[i]\n",
    "    if tokens:\n",
    "        df.loc[i, 'jaccard_gpt'] = jaccard_similarity(set(tokens_chatgpt), set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7759e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 1.5592236481706745\n",
      "P-Value: 0.11997035129475946\n"
     ]
    }
   ],
   "source": [
    "result_df_0 = df[df['condition_experiment'] == 0]['jaccard_gpt']\n",
    "result_df_1 = df[df['condition_experiment'] == 1]['jaccard_gpt']\n",
    "\n",
    "column_0 = result_df_0.sort_values()\n",
    "column_1 = result_df_1.sort_values()\n",
    "\n",
    "# Perform the t-test\n",
    "t_statistic, p_value = stats.ttest_ind(column_0, column_1, nan_policy='omit')\n",
    "\n",
    "# Display the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "184e1139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     jaccard_gpt  jaccard_gpt\n",
      "133     0.521739     0.452830\n",
      "134     0.521739     0.454545\n",
      "135     0.522727     0.500000\n",
      "136     0.549020     0.519231\n",
      "137     0.549020     0.529412\n",
      "138     0.555556     0.571429\n",
      "139     0.557692     0.581818\n",
      "140     0.571429     0.590909\n",
      "141     0.577778     0.596154\n",
      "142     0.584906     0.625000\n",
      "143     0.641509     0.625000\n",
      "144     0.652174     0.644444\n",
      "145     0.680851     0.666667\n",
      "146     0.681818     0.674419\n",
      "147     0.744681     0.674419\n",
      "148     0.790698     0.674419\n",
      "149     0.818182     0.714286\n",
      "150     0.921053     0.750000\n",
      "151     0.923077     0.923077\n",
      "152     0.947368     0.947368\n",
      "153          NaN     1.000000\n",
      "154          NaN     1.000000\n",
      "155          NaN     1.000000\n",
      "156          NaN     1.000000\n",
      "157          NaN          NaN\n"
     ]
    }
   ],
   "source": [
    "sorted_result_df_0 = result_df_0.sort_values().reset_index(drop=True)\n",
    "sorted_result_df_1 = result_df_1.sort_values().reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrames\n",
    "print(pd.concat([sorted_result_df_0, sorted_result_df_1], axis=1).tail(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15bc76",
   "metadata": {},
   "source": [
    "# Calculating jaccard distance between GPT and initial writing for control and treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12cafc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -7.9014127991289955\n",
      "P-Value: 4.733774934507111e-14\n"
     ]
    }
   ],
   "source": [
    "#tokens_treatment1 = df['Q10'].apply(tokenize_text)\n",
    "#tokens_treatment2 = df['Q12'].apply(tokenize_text)\n",
    "#tokens_control1 = df['Q14'].apply(tokenize_text)\n",
    "#tokens_control2 = df['Q17'].apply(tokenize_text)\n",
    "\n",
    "for i in df.index:\n",
    "    tokens1 = tokens_treatment1[i]\n",
    "    tokens2 = tokens_chatgpt\n",
    "    if tokens1 and tokens2:\n",
    "        df.loc[i, 'jaccard_gpt_initial'] = jaccard_similarity(set(tokens1), set(tokens2))\n",
    "    tokens1 = tokens_control1[i]\n",
    "    tokens2 = tokens_chatgpt\n",
    "    if tokens1 and tokens2:\n",
    "        df.loc[i, 'jaccard_gpt_initial'] = jaccard_similarity(set(tokens1), set(tokens2))\n",
    "\n",
    "gpt_initial_0 = df[df['condition_experiment'] == 0]['jaccard_gpt_initial']\n",
    "gpt_final_0 = df[df['condition_experiment'] == 0]['jaccard_gpt']\n",
    "gpt_initial_1 = df[df['condition_experiment'] == 1]['jaccard_gpt_initial']\n",
    "gpt_final_1 = df[df['condition_experiment'] == 1]['jaccard_gpt']\n",
    "\n",
    "column_0 = gpt_initial_1.sort_values()\n",
    "column_1 = gpt_final_1.sort_values()\n",
    "\n",
    "# Perform the t-test\n",
    "t_statistic, p_value = stats.ttest_ind(column_0, column_1, nan_policy='omit')\n",
    "\n",
    "# Display the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7425d",
   "metadata": {},
   "source": [
    "# Save output for Jaccard indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a0f5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/'.join(['output','jaccard_analysis_extended.csv']), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
